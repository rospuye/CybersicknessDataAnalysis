#
# ------ INSTRUCTIONS ------
# In order for everything to work correctly, the folder structure should be:
#
# ├── script.py
# ├── APP_DATA/
# │   ├── id1.csv
# │   ├── id2.csv
# │   └── (...)
# └── export.xml
#
# where script.py is this script, APP_DATA contains all the CSV files generated by the
# Unity application and export.xml is the XML file exported from the Apple Watch.
#
# ------ RESULTS ------
# Inside its own folder, this script will create the following structure:
#
# └── BIOMETRIC_RESULTS/
#     ├── id1/
#     │   ├── heartbeat_seated_avatar.csv
#     │   ├── heartbeat_seated_noavatar.csv
#     │   ├── heartbeat_walking_avatar.csv
#     │   └── heartbeat_walking_noavatar.csv
#     ├── id2/
#     │   └── (...)
#     └── (...)
#
# where the IDs correspond to those naming the APP_DATA CSV files and where, for each user
# and each scenario, it'll save heartbeat information, also in a CSV file.
#

import xml.etree.ElementTree as ET
from datetime import datetime, timezone
import re
import numpy as np
import pandas as pd
import csv
import os
import json
import glob

def extract_scenario_information(file_path):
    with open(file_path, 'r') as file:
        lines = file.readlines()
    
    scenarios = {}
    current_scenario = None
    for line in lines:
        line = line.strip()
        if line.startswith("SCENARIO_"):
            current_scenario = line
            scenarios[current_scenario] = []
        elif line.startswith("TimerStopped"):
            continue
        elif line.startswith("Timestamp,MovementDeltaX,MovementDeltaY,MovementDeltaZ,TotalMovementDelta"):
            continue
        elif current_scenario:
            scenarios[current_scenario].append(line)
    
    return scenarios

def get_start_and_end_timestamps(scenario_lines):
    first_line = scenario_lines[0]
    last_line = scenario_lines[-1]

    # string timestamps
    timestamp_start_str = first_line.split(",")[0]
    timestamp_end_str = last_line.split(",")[0]

    # turn them into datetime objects
    timestamp_start = datetime.strptime(timestamp_start_str, "%m/%d/%Y %I:%M:%S %p")
    timestamp_end = datetime.strptime(timestamp_end_str, "%m/%d/%Y %I:%M:%S %p")

    # add timezone to make it the same as the Apple Watch format
    timestamp_start = timestamp_start.replace(tzinfo=timezone.utc)
    timestamp_end = timestamp_end.replace(tzinfo=timezone.utc)

    return timestamp_start, timestamp_end

def format_iso_string(iso_string):
    """
    Adjusts the Apple Watch's timezone offset format in a given datetime string to ensure
    compatibility with the datetime library for proper parsing and interpretation.
    """
    pattern = r"([+-]\d{2})(\d{2})$"
    formatted_string = re.sub(pattern, r"\1:\2", iso_string.strip())
    return formatted_string

def remove_timezone_offset(iso_string):
    """
    Removes timezone offset from an ISO 8601 datetime string.
    """
    dt = datetime.fromisoformat(iso_string)
    return dt.replace(tzinfo=None).isoformat()

def find_relevant_records(xml_file, start, end, type):
    """
    Finds all Record tags whose 'startDate' and 'endDate' attributes are included within
    the timespan between 'start' and 'end', and whose 'type' attribute is the same as
    the input 'type'.
    """
    tree = ET.parse(xml_file)
    root = tree.getroot()
    
    records = []
    
    for record in root.findall('.//Record'):
        recordType = record.get('type')
        if (recordType != type):
            continue

        start_date = format_iso_string(record.get('startDate'))
        end_date = format_iso_string(record.get('endDate'))

        if start_date and end_date:
            record_start_dt = datetime.fromisoformat(start_date)
            record_end_dt = datetime.fromisoformat(end_date)
            
            if start <= record_start_dt and end >= record_end_dt:
                records.append(record)

    return records

def extract_ssq_information(filepath):

    with open(filepath, newline='') as csvfile:
        reader = csv.reader(csvfile)
        updated_rows = []
            
        for row in reader:

            # these tests went undone or incomplete and should not be considered
            if (row[1] == "t12" or row[1] == "t16"):
                continue

            updated_row = [

                False if cell == "No / Não"
                else True if cell == "Yes / Sim"

                else 0 if cell == "None / Inexistente"
                else 1 if cell == "Mild / Leve"
                else 2 if cell == "Moderate / Moderado"
                else 3 if cell == "Severe / Severo"

                else "AS" if cell == "Avatar + Seated / Avatar + Sentado(a)"
                else "NS" if cell == "No Avatar + Seated / Sem Avatar + Sentado(a)"
                else "AW" if cell == "Avatar + Walking / Avatar + Movimento"
                else "NW" if cell == "No Avatar + Walking / Sem Avatar + Movimento"

                else True if cell == "Yes, I'm ready / Sim, estou pronto(a)"
                else False if cell == "End experiment early / Terminar a experiência mais cedo"

                else cell
                
                for cell in row
            ]
            updated_rows.append(updated_row)

    ssq_data = {}
    for row in updated_rows:
        ssq_data[row[1]] = {
            "timestamp": row[0],
            "baseline": {
                "sickness": row[2],
                "general_discomfort": row[3],
                "fatigue": row[4],
                "headache": row[5],
                "eyestrain": row[6],
                "difficulty_focusing": row[7],
                "increased_salivation": row[8],
                "sweating": row[9],
                "nausea": row[10],
                "blurred_vision": row[11],
                "dizziness": row[12],
                "burping": row[13],
            },
            row[14]: {
                "sickness": row[15],
                "general_discomfort": row[16],
                "fatigue": row[17],
                "headache": row[18],
                "eyestrain": row[19],
                "difficulty_focusing": row[20],
                "increased_salivation": row[21],
                "sweating": row[22],
                "nausea": row[23],
                "blurred_vision": row[24],
                "dizziness": row[25],
                "burping": row[26],
            },
            row[28]: {
                "sickness": row[29],
                "general_discomfort": row[30],
                "fatigue": row[31],
                "headache": row[32],
                "eyestrain": row[33],
                "difficulty_focusing": row[34],
                "increased_salivation": row[35],
                "sweating": row[36],
                "nausea": row[37],
                "blurred_vision": row[38],
                "dizziness": row[39],
                "burping": row[40],
            },
            row[42]: {
                "sickness": row[43],
                "general_discomfort": row[44],
                "fatigue": row[45],
                "headache": row[46],
                "eyestrain": row[47],
                "difficulty_focusing": row[48],
                "increased_salivation": row[49],
                "sweating": row[50],
                "nausea": row[51],
                "blurred_vision": row[52],
                "dizziness": row[53],
                "burping": row[54],
            },
            row[56]: {
                "sickness": row[57],
                "general_discomfort": row[58],
                "fatigue": row[59],
                "headache": row[60],
                "eyestrain": row[61],
                "difficulty_focusing": row[62],
                "increased_salivation": row[63],
                "sweating": row[64],
                "nausea": row[65],
                "blurred_vision": row[66],
                "dizziness": row[67],
                "burping": row[68],
            },
        }

    return ssq_data

# ---------------------------------------------------------------------------------

def compute_head_movement_metrics(data):
    metrics = {}
    
    for scenario, movement_values in data.items():
        total_motion = 0
        angular_velocity = []
        timestamps = []
        
        previous_time = None
        previous_total_delta = None
        
        for data_point in movement_values:
            timestamp, _, _, _, total_delta = data_point.split(',')
            timestamp = datetime.strptime(timestamp, '%m/%d/%Y %I:%M:%S %p')
            total_delta = float(total_delta)
            total_motion += total_delta
            
            if previous_time is not None:
                time_diff = (timestamp - previous_time).total_seconds()
                velocity = (total_delta - previous_total_delta) / time_diff
                angular_velocity.append(velocity)
                timestamps.append(timestamp)
            
            previous_time = timestamp
            previous_total_delta = total_delta
        
        angular_acceleration = [
            (angular_velocity[i] - angular_velocity[i - 1]) / 
            (timestamps[i] - timestamps[i - 1]).total_seconds()
            for i in range(1, len(angular_velocity))
        ]
        
        avg_angular_velocity = sum(angular_velocity) / len(angular_velocity) if angular_velocity else 0
        avg_angular_acceleration = sum(angular_acceleration) / len(angular_acceleration) if angular_acceleration else 0
        
        metrics[scenario] = {
            'total_motion': total_motion,
            'average_angular_velocity': avg_angular_velocity,
            'average_angular_acceleration': avg_angular_acceleration
        }

    return metrics

def compute_heartbeat_metrics(data):
    metrics = {}

    for scenario, heartbeat_values in data.items():
        bpm_values = [int(data_point[2]) for data_point in heartbeat_values]
        hrv = np.std(bpm_values).item()
        average_bpm = np.mean(bpm_values).item()
        metrics[scenario] = {
            "hrv": hrv,
            "average_bpm": average_bpm
        }

    return metrics

# ---------------------------------------------------------------------------------

if __name__ == "__main__":

    folder_path = "APP_DATA"
    xml_file = "export.xml"
    csv_files = glob.glob(os.path.join(folder_path, "*.csv"))

    for application_file in csv_files:

        id = os.path.splitext(os.path.basename(application_file))[0]
        if (id in ["t12", "t16", "t19", "t26", "t27"]):
            continue

        application_data = extract_scenario_information(application_file)

        heartbeat_data = {}
        for scenario, lines in application_data.items():
            shortened_scenario = scenario.replace("SCENARIO_", "", 1)
            start, end = get_start_and_end_timestamps(lines)

            heartBeatType = "HKQuantityTypeIdentifierHeartRate"

            heartbeat_records = find_relevant_records(xml_file, start, end, heartBeatType)

            heartbeat = [[r.get('startDate'), r.get('endDate'), r.get('value')] for r in heartbeat_records]
            heartbeat_data[scenario] = heartbeat

            folder_name = f"BIOMETRIC_RESULTS/{id}"
            os.makedirs(folder_name, exist_ok=True)

            with open(f'{folder_name}/heartbeat_{shortened_scenario}.csv', mode='w', newline='') as file:
                writer = csv.writer(file)
                writer.writerows(heartbeat_data[scenario])

        # head_movement_metrics = compute_head_movement_metrics(application_data)
        heartbeat_metrics = compute_heartbeat_metrics(heartbeat_data)

        metrics_folder_name = f"METRICS/{id}"
        os.makedirs(metrics_folder_name, exist_ok=True)
        # with open(f'{metrics_folder_name}/head_movement_metrics.json', mode='w', newline='') as file:
        #     json.dump(head_movement_metrics, file)
        with open(f'{metrics_folder_name}/heartbeat_metrics.json', mode='w', newline='') as file:
            json.dump(heartbeat_metrics, file)


    # ssq_data = extract_ssq_information('ssq.csv')
    # with open('ssq.json', mode='w', newline='') as file:
    #     json.dump(ssq_data, file)
